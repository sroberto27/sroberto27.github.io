[
  {
    "id": 1,
    "title": "A Survey on Virtual Production and the Future of Compositing Technologies",
    "authors": ["Filipe L. Pires", "Rui Silva", "Rui Raposo"],
    "year": 2022,
    "source": "AVANCA-CINEMA 2022 (Int'l Conf.)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "A comprehensive survey covering virtual production techniques and compositing technologies, reviewing the state of the art and projecting future developments in real-time filmmaking pipelines.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "2D Images/Video", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist", "Cinematographer/DP"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["survey", "compositing", "real-time rendering", "virtual production"]
  },
  {
    "id": 2,
    "title": "The Emergence of Virtual Production – A Research Agenda",
    "authors": ["Jon Swords", "Nina Willment"],
    "year": 2024,
    "source": "Convergence (Journal, in press)",
    "sourceType": "Journal",
    "doi": "",
    "url": "https://xrstories.co.uk/wp-content/uploads/2024/06/swords-willment-2024-the-emergence-of-virtual-production-a-research-agenda.pdf",
    "abstract": "Proposes a research agenda for virtual production, framing it as an emergent assemblage of technologies and workflows that resists neat definition due to rapid evolution of methods and use cases.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Remote Collaboration"],
    "xrModality": ["VR", "AR", "MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["System Control (UI interaction)"],
    "dataFormats": ["Game Engine/Scene Files", "Metadata/Script Data"],
    "targetRoles": ["Director", "Producer/Coordinator", "VFX Supervisor/Artist"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["research agenda", "definitions", "industry analysis", "emerging technology"]
  },
  {
    "id": 3,
    "title": "Envisioning the Future of Virtual Production in Film-Making: A Remote Co-Design Study",
    "authors": ["Alessio Bodini", "et al."],
    "year": 2023,
    "source": "Multimedia Tools & Applications (Journal)",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Explores future virtual production design through remote co-design sessions with industry professionals, identifying key opportunities and challenges for collaborative filmmaking in XR.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Remote Collaboration", "Previsualization & Storyboarding", "On-Set Visualization (Virtual Production)"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["VR HMD (Tethered)", "Projection/Spatial Display"],
    "coreInteraction": ["Collaboration Mechanisms", "Selection & Manipulation", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Production Designer/Art Department", "VFX Supervisor/Artist"],
    "evaluation": ["User Study (Formal)", "Qualitative Analysis"],
    "reportedOutcomes": ["Enhanced Collaboration", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["co-design", "remote collaboration", "future vision", "participatory design"]
  },
  {
    "id": 4,
    "title": "The Virtual Production Studio Concept – An Emerging Game Changer in Filmmaking",
    "authors": ["Manolya Kavakli", "Cinzia Cremona"],
    "year": 2022,
    "source": "IEEE VR 2022 (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Introduces the virtual production studio concept as a transformative approach to filmmaking, detailing technical architecture and workflow integration for real-time LED wall environments.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control", "Navigation/Travel"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["LED wall", "virtual production studio", "game changer", "IEEE VR"]
  },
  {
    "id": 5,
    "title": "How to Reduce Input Lag in a Virtual Production Studio",
    "authors": ["Manolya Kavakli"],
    "year": 2022,
    "source": "HCI Int'l 2022 Posters (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Addresses the critical challenge of input lag in virtual production studios, proposing techniques for latency reduction to improve real-time rendering feedback on LED walls.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["VFX Supervisor/Artist", "Cinematographer/DP"],
    "evaluation": ["Controlled Experiment (Quantitative Metrics)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["latency", "input lag", "LED wall", "performance optimization"]
  },
  {
    "id": 6,
    "title": "Virtual Production and Real-Time Filmmaking Technologies for Independent Filmmakers: An Overview",
    "authors": ["Volker Kuchelmeister"],
    "year": 2020,
    "source": "FKT Journal (Film/TV Tech)",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Provides an overview of accessible virtual production and real-time filmmaking technologies for independent filmmakers, emphasizing democratization of professional-grade tools.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Standalone)", "Mobile Device (Handheld AR)"],
    "coreInteraction": ["Perspective/Camera Control", "Selection & Manipulation"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Cinematographer/DP", "Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["independent film", "democratization", "accessible tools", "real-time"]
  },
  {
    "id": 7,
    "title": "Adopting Virtual Production for Animated Filmmaking",
    "authors": ["J. Scott Bennett", "Chris P. Carter"],
    "year": 2014,
    "source": "CGAT 2014 (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Examines the adoption of virtual production techniques in animated filmmaking, discussing workflows that blend traditional animation with real-time virtual production approaches.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Previsualization & Storyboarding", "On-Set Visualization (Virtual Production)"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Tethered)", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control", "Selection & Manipulation"],
    "dataFormats": ["3D Models/Assets", "Motion/Tracking Data", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["animation", "early adoption", "motion capture", "workflow"]
  },
  {
    "id": 8,
    "title": "Virtual Production and the Transformation of Cameras: Mechanical, Virtual, and Actual",
    "authors": ["Patrick Bédart"],
    "year": 2022,
    "source": "Animation (SAGE Journal)",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Analyzes how virtual production transforms the concept and role of the camera across mechanical, virtual, and actual modalities, examining implications for cinematographic practice.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["Motion/Tracking Data", "Game Engine/Scene Files"],
    "targetRoles": ["Cinematographer/DP", "Director"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["camera transformation", "cinematography", "theory", "camera tracking"]
  },
  {
    "id": 9,
    "title": "The Role of the Embodiment Director in Virtual Reality Film Production",
    "authors": ["Rafael Carpio", "Jodi Birt"],
    "year": 2022,
    "source": "Creative Industries Journal",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Proposes the role of 'embodiment director' as a new crew position in VR film production, responsible for guiding viewer presence and agency in immersive narrative experiences.",
    "pipelineStages": ["Production"],
    "useCases": ["Immersive Storytelling (XR Content Creation)"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Tethered)", "VR HMD (Standalone)"],
    "coreInteraction": ["Navigation/Travel", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "2D Images/Video"],
    "targetRoles": ["Director", "Actor/Performer"],
    "evaluation": ["Qualitative Analysis"],
    "reportedOutcomes": ["Creative Enablement", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["embodiment", "VR film", "directing", "new roles", "immersive narrative"]
  },
  {
    "id": 10,
    "title": "Curricular Design Experiences for Virtual Production: Multi-Institutional Examples",
    "authors": ["Mayet Andreassen", "et al."],
    "year": 2025,
    "source": "ACM SIGGRAPH Educator's Forum 2025",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Presents multi-institutional curricular design experiences for teaching virtual production, sharing pedagogical approaches and outcomes across different academic programs.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["Training & Rehearsal"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "VR HMD (Tethered)"],
    "coreInteraction": ["System Control (UI interaction)", "Perspective/Camera Control"],
    "dataFormats": ["Game Engine/Scene Files", "3D Models/Assets"],
    "targetRoles": ["Other Crew"],
    "evaluation": ["Qualitative Analysis", "Case Study (In-situ)"],
    "reportedOutcomes": ["Learning/Training Outcomes"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["education", "curriculum", "training", "pedagogy", "multi-institutional"]
  },
  {
    "id": 11,
    "title": "XRStudio: A Virtual Production and Live Streaming System for Immersive Instructional Experiences",
    "authors": ["Michael Nebeling", "et al."],
    "year": 2021,
    "source": "CHI 2021 (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Presents XRStudio, a system combining virtual production with live streaming for immersive instructional experiences, enabling presenters to interact with 3D content in real time.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Immersive Storytelling (XR Content Creation)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Selection & Manipulation", "Perspective/Camera Control", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "2D Images/Video", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Other Crew"],
    "evaluation": ["User Study (Formal)", "Qualitative Analysis"],
    "reportedOutcomes": ["Higher User Satisfaction/Usability", "Creative Enablement"],
    "openScience": "Code Available (Open-Source)",
    "maturity": "Prototype",
    "tags": ["XRStudio", "live streaming", "instruction", "CHI", "mixed reality"]
  },
  {
    "id": 12,
    "title": "Pioneers in Machinima: The Grassroots of Virtual Production",
    "authors": ["Tracy Harwood", "Ben Grussi"],
    "year": 2021,
    "source": "Vernon Press (Book)",
    "sourceType": "Book",
    "doi": "",
    "url": "",
    "abstract": "Explores the grassroots origins of virtual production through the machinima movement, tracing how game-engine-based filmmaking pioneered techniques now used in professional VP.",
    "pipelineStages": ["Production", "Post-production"],
    "useCases": ["Immersive Storytelling (XR Content Creation)"],
    "xrModality": ["VR"],
    "platformHardware": ["Other Peripherals"],
    "coreInteraction": ["Perspective/Camera Control", "Selection & Manipulation"],
    "dataFormats": ["Game Engine/Scene Files", "2D Images/Video"],
    "targetRoles": ["Director", "VFX Supervisor/Artist"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["machinima", "history", "grassroots", "game engine filmmaking"]
  },
  {
    "id": 13,
    "title": "Virtual Production: A New Approach to Filmmaking",
    "authors": ["Oleksandr Priadko", "Maksym Sirenko"],
    "year": 2021,
    "source": "Bulletin of KNUCA, 4(1):52–58",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Introduces virtual production as a new approach to filmmaking in the Ukrainian context, describing key technologies and their potential impact on local film industry workflows.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Cinematographer/DP"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["introduction", "overview", "filmmaking approach"]
  },
  {
    "id": 14,
    "title": "Dreamspace: A Platform and Tools for Collaborative Virtual Production",
    "authors": ["O. Grau", "et al."],
    "year": 2017,
    "source": "SMPTE Motion Imaging Journal, 126(6):29–36",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Presents the Dreamspace platform for collaborative virtual production, enabling multiple users to interact in shared virtual environments for planning and executing film productions.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Remote Collaboration", "Previsualization & Storyboarding", "On-Set Visualization (Virtual Production)"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["VR HMD (Tethered)", "Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Collaboration Mechanisms", "Selection & Manipulation", "Navigation/Travel"],
    "dataFormats": ["3D Models/Assets", "Motion/Tracking Data", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Production Designer/Art Department", "VFX Supervisor/Artist"],
    "evaluation": ["User Study (Formal)", "Case Study (In-situ)"],
    "reportedOutcomes": ["Enhanced Collaboration", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["Dreamspace", "collaboration", "SMPTE", "multi-user", "platform"]
  },
  {
    "id": 15,
    "title": "VPET – Virtual Production Editing Tools",
    "authors": ["Simon Spielmann", "et al."],
    "year": 2018,
    "source": "ACM SIGGRAPH 2018 (Emerging Technologies)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Demonstrates VPET (Virtual Production Editing Tools), a set of tools for editing virtual production elements including set layout, lighting, and camera placement in real time.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Virtual Location Scouting/Set Design", "Previsualization & Storyboarding"],
    "xrModality": ["VR", "AR"],
    "platformHardware": ["VR HMD (Tethered)", "Mobile Device (Handheld AR)"],
    "coreInteraction": ["Selection & Manipulation", "Perspective/Camera Control", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Production Designer/Art Department", "Cinematographer/DP"],
    "evaluation": ["Expert Review/Feedback"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Higher User Satisfaction/Usability"],
    "openScience": "Code Available (Open-Source)",
    "maturity": "Prototype",
    "tags": ["VPET", "editing tools", "SIGGRAPH", "set design", "lighting"]
  },
  {
    "id": 16,
    "title": "Next Level Consumer Devices for Virtual Production",
    "authors": ["Volker Helzle", "Simon Spielmann"],
    "year": 2017,
    "source": "CVMP 2017 (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Explores the use of consumer-grade devices (smartphones, tablets, consumer VR headsets) for virtual production, lowering the barrier to entry for VP workflows.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Previsualization & Storyboarding", "Virtual Location Scouting/Set Design"],
    "xrModality": ["AR", "VR"],
    "platformHardware": ["Mobile Device (Handheld AR)", "VR HMD (Standalone)"],
    "coreInteraction": ["Selection & Manipulation", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Production Designer/Art Department"],
    "evaluation": ["Expert Review/Feedback"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["consumer devices", "accessibility", "mobile", "CVMP"]
  },
  {
    "id": 17,
    "title": "Intuitive Virtual Production Tools for Set and Light Editing",
    "authors": ["Jonas Trottnow", "et al."],
    "year": 2015,
    "source": "CVMP 2015 (Conference)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Presents intuitive tools for virtual production that allow set designers and lighting artists to edit sets and lighting setups within virtual environments using natural interaction techniques.",
    "pipelineStages": ["Pre-production"],
    "useCases": ["Virtual Location Scouting/Set Design"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Tethered)", "Other Peripherals"],
    "coreInteraction": ["Selection & Manipulation", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Production Designer/Art Department", "Cinematographer/DP"],
    "evaluation": ["User Study (Formal)"],
    "reportedOutcomes": ["Higher User Satisfaction/Usability", "Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["set design", "lighting", "intuitive tools", "CVMP", "foundational"]
  },
  {
    "id": 18,
    "title": "Genesis: A Pipeline for Virtual Production",
    "authors": ["Robert Tovell", "Nina Williams"],
    "year": 2018,
    "source": "DigiPro 2018 (ACM Digital Production Symposium)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Describes Genesis, a complete pipeline for virtual production developed by Technicolor, covering asset management, real-time rendering, and on-set integration workflows.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["MR"],
    "platformHardware": ["Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data", "Metadata/Script Data"],
    "targetRoles": ["Director", "VFX Supervisor/Artist", "Producer/Coordinator"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Improved Decision Quality"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["Genesis", "pipeline", "Technicolor", "asset management", "DigiPro"]
  },
  {
    "id": 19,
    "title": "Virtual Production in 'Book of the Dead': Technicolor's Genesis Platform, Powered by Unity",
    "authors": ["F. Giordana", "et al."],
    "year": 2018,
    "source": "SIGGRAPH 2018 (Real-Time Live!)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Demonstrates the Genesis virtual production platform powered by Unity in the creation of 'Book of the Dead', showcasing real-time rendering and virtual camera workflows.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["Unity", "Book of the Dead", "real-time demo", "SIGGRAPH"]
  },
  {
    "id": 20,
    "title": "Three Keys to Creating the World of 'Ready Player One' – VFX & Virtual Production",
    "authors": ["Grady Cofer", "et al."],
    "year": 2018,
    "source": "SIGGRAPH 2018 (Production Sessions)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Details the virtual production techniques used in 'Ready Player One', including virtual camera systems and real-time previsualization for Spielberg's direction of VR-world sequences.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Previsualization & Storyboarding", "On-Set Visualization (Virtual Production)"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Tethered)", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Navigation/Travel", "Perspective/Camera Control", "Selection & Manipulation"],
    "dataFormats": ["3D Models/Assets", "Motion/Tracking Data", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist", "Cinematographer/DP"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["Ready Player One", "Spielberg", "ILM", "VR previs", "blockbuster"]
  },
  {
    "id": 21,
    "title": "The 'Reflections' Ray-Tracing Demo Captured Live Using Virtual Production Techniques",
    "authors": ["Gavin Moran", "Mohen Leo"],
    "year": 2018,
    "source": "SIGGRAPH 2018 (Real-Time Live!)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Showcases a real-time ray-tracing demo captured live using virtual production techniques, demonstrating the potential of RTX hardware for photorealistic in-camera VFX.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Realism/Presence", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Prototype",
    "tags": ["ray tracing", "RTX", "real-time demo", "SIGGRAPH", "photorealistic"]
  },
  {
    "id": 22,
    "title": "Cinematic Space in Virtual Production",
    "authors": ["Katriina Ilmaranta"],
    "year": 2020,
    "source": "SALENTO AVR 2020 (Int. AR/VR Conf.)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Examines the concept of cinematic space in virtual production, analyzing how spatial design principles translate to LED wall environments and immersive filmmaking.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["Virtual Location Scouting/Set Design", "On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["Navigation/Travel", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Spatial Scans/Point Clouds"],
    "targetRoles": ["Production Designer/Art Department", "Director", "Cinematographer/DP"],
    "evaluation": ["Qualitative Analysis"],
    "reportedOutcomes": ["Creative Enablement", "Improved Decision Quality"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["cinematic space", "spatial design", "LED wall", "theory"]
  },
  {
    "id": 23,
    "title": "Colour-Managed LED Walls for Virtual Production",
    "authors": ["Oliver James", "et al."],
    "year": 2021,
    "source": "ACM SIGGRAPH 2021 (Talk)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Presents colour management techniques for LED walls in virtual production, addressing calibration, gamut mapping, and perceptual accuracy for in-camera visual effects.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["System Control (UI interaction)"],
    "dataFormats": ["2D Images/Video", "Game Engine/Scene Files"],
    "targetRoles": ["Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Controlled Experiment (Quantitative Metrics)"],
    "reportedOutcomes": ["Realism/Presence", "Improved Decision Quality"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["colour management", "LED wall", "calibration", "SIGGRAPH", "ICVFX"]
  },
  {
    "id": 24,
    "title": "Expanding Virtual Production Frontiers: AI-Driven Workflows for Enhanced Cinematic Creation",
    "authors": ["Junrong Song", "et al."],
    "year": 2025,
    "source": "VINCI 2025 (Int. Symp. Visual Comm & Interact)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Explores AI-driven workflows that expand virtual production capabilities, including neural rendering, generative environments, and automated camera planning for cinematic creation.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding", "Post-production Review"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "VR HMD (Tethered)"],
    "coreInteraction": ["System Control (UI interaction)", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "2D Images/Video", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["AI", "neural rendering", "generative", "future workflows", "automation"]
  },
  {
    "id": 25,
    "title": "Philosophical Perspectives on Realism in VP and XR in Film/TV",
    "authors": ["Aneta Postek"],
    "year": 2024,
    "source": "ICVR 2024 (Int. Conf. Virtual Reality)",
    "sourceType": "Conference",
    "doi": "",
    "url": "",
    "abstract": "Provides philosophical analysis of realism in virtual production and XR for film and television, examining ontological and perceptual implications of digitally mediated filmmaking.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Immersive Storytelling (XR Content Creation)"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "VR HMD (Tethered)"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets"],
    "targetRoles": ["Director"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["philosophy", "realism", "theory", "perception", "ontology"]
  },
  {
    "id": 26,
    "title": "Virtual Production Field Guide, Volume 1",
    "authors": ["Noah Kadner"],
    "year": 2019,
    "source": "Epic Games (White Paper e-book)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "The first volume of Epic Games' comprehensive field guide to virtual production, covering foundational concepts, Unreal Engine workflows, and practical implementation guidance.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding", "Virtual Location Scouting/Set Design"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig", "VR HMD (Tethered)"],
    "coreInteraction": ["Perspective/Camera Control", "Selection & Manipulation", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist", "Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "Data Available",
    "maturity": "Commercial/Production-Ready",
    "tags": ["field guide", "Unreal Engine", "Epic Games", "industry guide", "foundational"]
  },
  {
    "id": 27,
    "title": "Virtual Production Field Guide, Volume 2",
    "authors": ["Noah Kadner"],
    "year": 2021,
    "source": "Epic Games (White Paper e-book)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "The second volume expanding on virtual production practices with updated case studies, advanced LED wall techniques, and refined Unreal Engine virtual production workflows.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist", "Producer/Coordinator"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement", "Enhanced Collaboration"],
    "openScience": "Data Available",
    "maturity": "Commercial/Production-Ready",
    "tags": ["field guide", "Unreal Engine", "Epic Games", "LED wall", "advanced"]
  },
  {
    "id": 28,
    "title": "Technology-Driven Virtual Production: Game Engines in the Film Industry",
    "authors": ["Anjie Dong"],
    "year": 2022,
    "source": "Revista FAMECOS, 29:e43370",
    "sourceType": "Journal",
    "doi": "",
    "url": "",
    "abstract": "Examines the role of game engines in driving virtual production adoption in the film industry, analyzing technological affordances and industry transformation patterns.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["System Control (UI interaction)", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["game engines", "Unreal Engine", "Unity", "industry transformation"]
  },
  {
    "id": 29,
    "title": "Virtual Production: A Study on its Environmental Impact",
    "authors": ["C. Lejeune", "et al."],
    "year": 2022,
    "source": "Film Paris Region (Industry Report)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Studies the environmental impact of virtual production compared to traditional filmmaking, analyzing carbon footprint, energy consumption, and sustainability trade-offs.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": [],
    "dataFormats": ["Metadata/Script Data"],
    "targetRoles": ["Producer/Coordinator"],
    "evaluation": ["Controlled Experiment (Quantitative Metrics)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "Data Available",
    "maturity": "Concept",
    "tags": ["sustainability", "environmental impact", "carbon footprint", "green production"]
  },
  {
    "id": 30,
    "title": "Art of LED Wall Virtual Production – Lessons from The Mandalorian",
    "authors": ["Mike Seymour"],
    "year": 2020,
    "source": "FXGuide (Industry Article)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Provides an in-depth analysis of the LED wall virtual production techniques used in The Mandalorian, covering StageCraft technology, workflow innovations, and creative implications.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Efficiency Gains (Time/Cost)", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["Mandalorian", "StageCraft", "ILM", "LED wall", "case study"]
  },
  {
    "id": 31,
    "title": "ILM Case Study: Breaking New Ground in a Galaxy Far, Far Away",
    "authors": ["Vicon"],
    "year": 2021,
    "source": "Vicon Motion Systems (Case Study)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Documents Vicon's motion tracking technology deployment on ILM productions, focusing on camera and performer tracking systems used in virtual production for Star Wars properties.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["Motion/Tracking Data", "3D Models/Assets"],
    "targetRoles": ["Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["Vicon", "motion tracking", "ILM", "Star Wars", "camera tracking"]
  },
  {
    "id": 32,
    "title": "Virtual Production Hub: The Future of Filmmaking",
    "authors": ["Epic Games"],
    "year": 2021,
    "source": "Unreal Engine (Web Documentation)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Epic Games' central documentation hub for Unreal Engine virtual production, covering tools, tutorials, and best practices for real-time filmmaking workflows.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding", "Virtual Location Scouting/Set Design"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "VR HMD (Tethered)", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control", "Selection & Manipulation", "System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data", "2D Images/Video"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist", "Production Designer/Art Department"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement", "Efficiency Gains (Time/Cost)"],
    "openScience": "Data Available",
    "maturity": "Commercial/Production-Ready",
    "tags": ["Unreal Engine", "Epic Games", "documentation", "tools hub"]
  },
  {
    "id": 33,
    "title": "Virtual Production: It's the Future You Need to Know About",
    "authors": ["Damian Allen"],
    "year": 2019,
    "source": "ProVideo Coalition (Article)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "An industry perspective on the emerging importance of virtual production in filmmaking, discussing trends, tools, and implications for production professionals.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["Game Engine/Scene Files"],
    "targetRoles": ["Director", "Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["industry perspective", "future trends", "overview"]
  },
  {
    "id": 34,
    "title": "The Mandalorian: A Test Bed for Virtual Production",
    "authors": ["José Antunes"],
    "year": 2021,
    "source": "ProVideo Coalition (Article)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Analyzes The Mandalorian as a pivotal test bed for virtual production technologies, documenting how the show advanced LED wall ICVFX techniques for episodic television.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Realism/Presence", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["Mandalorian", "StageCraft", "ICVFX", "television", "case study"]
  },
  {
    "id": 35,
    "title": "Building a Greater Volume of Virtual Production",
    "authors": ["Michael Burns"],
    "year": 2021,
    "source": "IBC365 (Industry Insight)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Discusses the expansion of virtual production volumes across the industry, covering infrastructure needs, industry adoption patterns, and scaling challenges for LED wall stages.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": [],
    "dataFormats": ["Game Engine/Scene Files"],
    "targetRoles": ["Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["volume stage", "industry growth", "infrastructure", "scaling"]
  },
  {
    "id": 36,
    "title": "Virtual Production Innovation Series #1: Environmental Lighting",
    "authors": ["Jake Bickerton"],
    "year": 2022,
    "source": "Broadcast (Magazine series)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "First in a series on virtual production innovations, focusing on environmental lighting techniques using LED walls and real-time rendering for naturalistic on-set illumination.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Cinematographer/DP", "Other Crew"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Realism/Presence", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["lighting", "LED wall", "environmental light", "innovation"]
  },
  {
    "id": 37,
    "title": "Boost Virtual Production in Film and TV for Growth and Sustainability, Urge Experts",
    "authors": ["Adrian Slater"],
    "year": 2021,
    "source": "Screen Daily (News)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Industry experts urge increased adoption of virtual production for growth and sustainability in film and TV, discussing economic and environmental benefits.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": [],
    "dataFormats": [],
    "targetRoles": ["Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["sustainability", "industry growth", "policy", "advocacy"]
  },
  {
    "id": 38,
    "title": "How AR and VR Are Changing Film: The Revolutionary StageCraft 'Volume'",
    "authors": ["Katie Winter"],
    "year": 2021,
    "source": "CMU AMT Lab (Tech Blog)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Explains how AR and VR technologies are changing filmmaking through ILM's StageCraft Volume, covering the technical foundations and creative implications for the industry.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["AR", "MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Cinematographer/DP"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Creative Enablement", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["StageCraft", "Volume", "AR/VR", "ILM", "revolution"]
  },
  {
    "id": 39,
    "title": "Generative A.I. Accelerates Virtual Production",
    "authors": ["Noah Kadner"],
    "year": 2022,
    "source": "VirtualProducer.io (Blog)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Explores how generative AI tools are accelerating virtual production workflows, from environment generation to asset creation and automated compositing.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Previsualization & Storyboarding"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": ["System Control (UI interaction)"],
    "dataFormats": ["3D Models/Assets", "2D Images/Video", "Game Engine/Scene Files"],
    "targetRoles": ["VFX Supervisor/Artist", "Production Designer/Art Department"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)", "Creative Enablement"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["generative AI", "automation", "asset generation", "future"]
  },
  {
    "id": 40,
    "title": "The Mandalorian: This Is The Way",
    "authors": ["Jeff Holben"],
    "year": 2020,
    "source": "American Cinematographer (Feb 2020)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "American Cinematographer's coverage of The Mandalorian's cinematographic innovations, detailing how virtual production enabled new approaches to lighting, camera work, and visual storytelling.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files", "Motion/Tracking Data"],
    "targetRoles": ["Cinematographer/DP", "Director"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Realism/Presence"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["Mandalorian", "cinematography", "lighting", "American Cinematographer"]
  },
  {
    "id": 41,
    "title": "Why 'The Jungle Book' Skipped Location Shoots in Favor of Virtual Production",
    "authors": ["Carolyn Giardina"],
    "year": 2017,
    "source": "Hollywood Reporter (Feb 2017)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Reports on how The Jungle Book (2016) pioneered virtual production by eliminating traditional location shoots, using complete virtual environments for all outdoor scenes.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Virtual Location Scouting/Set Design"],
    "xrModality": ["VR"],
    "platformHardware": ["VR HMD (Tethered)", "Tracking System / Tracked Rig", "Projection/Spatial Display"],
    "coreInteraction": ["Navigation/Travel", "Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Motion/Tracking Data", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Deployed/Pilot",
    "tags": ["Jungle Book", "Disney", "pioneer", "virtual environments", "location replacement"]
  },
  {
    "id": 42,
    "title": "'1899' – Netflix & Dark Creators on Europe's Largest Virtual Production Stage",
    "authors": ["Tom Grater"],
    "year": 2022,
    "source": "Deadline (May 3, 2022)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Covers the creation of Netflix's '1899' on Europe's largest virtual production stage, documenting the technical setup, creative process, and production challenges.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["MR"],
    "platformHardware": ["Projection/Spatial Display", "Tracking System / Tracked Rig"],
    "coreInteraction": ["Perspective/Camera Control"],
    "dataFormats": ["3D Models/Assets", "Game Engine/Scene Files"],
    "targetRoles": ["Director", "Cinematographer/DP", "VFX Supervisor/Artist"],
    "evaluation": ["Case Study (In-situ)"],
    "reportedOutcomes": ["Creative Enablement", "Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Commercial/Production-Ready",
    "tags": ["1899", "Netflix", "Dark", "European VP", "large-scale"]
  },
  {
    "id": 43,
    "title": "Lights, Camera… Anyone? Film Studios Can't Get the Crew",
    "authors": ["M. Kahn"],
    "year": 2021,
    "source": "Reuters (Nov 24, 2021)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Reports on the industry-wide crew shortage affecting film and TV production, providing context for virtual production's potential to reduce on-set staffing requirements.",
    "pipelineStages": ["Production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": [],
    "platformHardware": [],
    "coreInteraction": [],
    "dataFormats": [],
    "targetRoles": ["Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["crew shortage", "industry challenge", "workforce", "labor"]
  },
  {
    "id": 44,
    "title": "Shortage of Skilled Film/TV Workers Could Threaten Production Boom",
    "authors": ["Taylor Simmons"],
    "year": 2022,
    "source": "CBC News (Jul 11, 2022)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Examines how the shortage of skilled film and TV workers threatens the ongoing production boom, with implications for virtual production adoption as a mitigation strategy.",
    "pipelineStages": ["Production"],
    "useCases": ["Training & Rehearsal"],
    "xrModality": [],
    "platformHardware": [],
    "coreInteraction": [],
    "dataFormats": [],
    "targetRoles": ["Producer/Coordinator", "Other Crew"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Learning/Training Outcomes"],
    "openScience": "No (Closed)",
    "maturity": "Concept",
    "tags": ["skills shortage", "training", "workforce development", "industry challenge"]
  },
  {
    "id": 45,
    "title": "Virtual Production: A Global Innovation Opportunity for the UK",
    "authors": ["StoryFutures Academy"],
    "year": 2021,
    "source": "Immersive Skills Report (UK)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Assesses virtual production as a global innovation opportunity for the UK creative industries, mapping skills needs, infrastructure requirements, and growth potential.",
    "pipelineStages": ["Pre-production", "Production"],
    "useCases": ["On-Set Visualization (Virtual Production)", "Training & Rehearsal"],
    "xrModality": ["VR", "MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": [],
    "dataFormats": [],
    "targetRoles": ["Producer/Coordinator", "Other Crew"],
    "evaluation": ["Qualitative Analysis"],
    "reportedOutcomes": ["Learning/Training Outcomes", "Efficiency Gains (Time/Cost)"],
    "openScience": "Data Available",
    "maturity": "Concept",
    "tags": ["UK", "skills report", "innovation", "policy", "industry growth"]
  },
  {
    "id": 46,
    "title": "Virtual Production Market Worth $6.79 Billion by 2030",
    "authors": ["Grand View Research"],
    "year": 2022,
    "source": "Market Analysis (Industry Report)",
    "sourceType": "Industry Report",
    "doi": "",
    "url": "",
    "abstract": "Market analysis projecting the virtual production market to reach $6.79 billion by 2030, covering market segmentation, growth drivers, and regional adoption patterns.",
    "pipelineStages": ["Pre-production", "Production", "Post-production"],
    "useCases": ["On-Set Visualization (Virtual Production)"],
    "xrModality": ["VR", "AR", "MR"],
    "platformHardware": ["Projection/Spatial Display"],
    "coreInteraction": [],
    "dataFormats": [],
    "targetRoles": ["Producer/Coordinator"],
    "evaluation": ["No Formal Evaluation (Demo/Analysis)"],
    "reportedOutcomes": ["Efficiency Gains (Time/Cost)"],
    "openScience": "Data Available",
    "maturity": "Concept",
    "tags": ["market analysis", "growth projection", "$6.79B", "industry forecast"]
  }
]
